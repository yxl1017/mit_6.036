{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "642e77ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 13:17:35.050705: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-17 13:17:35.096981: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-17 13:17:35.097761: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 13:17:35.862866: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import math as m \n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Conv1D, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras.initializers import VarianceScaling\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b9872f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Problem 3 - 2D data\n",
    "######################################################################\n",
    "\n",
    "def archs(classes):\n",
    "    return [[Dense(input_dim=2, units=classes, activation=\"softmax\")],\n",
    "            [Dense(input_dim=2, units=10, activation='relu'),\n",
    "             Dense(units=classes, activation=\"softmax\")],\n",
    "            [Dense(input_dim=2, units=100, activation='relu'),\n",
    "             Dense(units=classes, activation=\"softmax\")],\n",
    "            [Dense(input_dim=2, units=10, activation='relu'),\n",
    "             Dense(units=10, activation='relu'),\n",
    "             Dense(units=classes, activation=\"softmax\")],\n",
    "            [Dense(input_dim=2, units=100, activation='relu'),\n",
    "             Dense(units=100, activation='relu'),\n",
    "             Dense(units=classes, activation=\"softmax\")]]\n",
    "\n",
    "# Read the simple 2D dataset files\n",
    "def get_data_set(name):\n",
    "    try:\n",
    "        data = np.loadtxt(name, skiprows=0, delimiter = ' ')\n",
    "    except:\n",
    "        return None, None, None\n",
    "    np.random.shuffle(data)             # shuffle the data\n",
    "    # The data uses ROW vectors for a data point, that's what Keras assumes.\n",
    "    _, d = data.shape\n",
    "    X = data[:,0:d-1]\n",
    "    Y = data[:,d-1:d]\n",
    "    y = Y.T[0]\n",
    "    classes = set(y)\n",
    "    if classes == set([-1.0, 1.0]):\n",
    "        print('Convert from -1,1 to 0,1')\n",
    "        y = 0.5*(y+1)\n",
    "    print('Loading X', X.shape, 'y', y.shape, 'classes', set(y))\n",
    "    return X, y, len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca00a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# General helpers for Problems 3-5\n",
    "######################################################################\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.keys = ['loss', 'acc', 'val_loss', 'val_acc']\n",
    "        self.values = {}\n",
    "        for k in self.keys:\n",
    "            self.values['batch_'+k] = []\n",
    "            self.values['epoch_'+k] = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        for k in self.keys:\n",
    "            bk = 'batch_'+k\n",
    "            if k in logs:\n",
    "                self.values[bk].append(logs[k])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        for k in self.keys:\n",
    "            ek = 'epoch_'+k\n",
    "            if k in logs:\n",
    "                self.values[ek].append(logs[k])\n",
    "\n",
    "    def plot(self, keys):\n",
    "        for key in keys:\n",
    "            plt.plot(np.arange(len(self.values[key])), np.array(self.values[key]), label=key)\n",
    "        plt.legend()\n",
    "\n",
    "def run_keras(X_train, y_train, X_val, y_val, X_test, y_test, layers, epochs, split=0, verbose=True):\n",
    "    # Model specification\n",
    "    model = Sequential()\n",
    "    for layer in layers:\n",
    "        model.add(layer)\n",
    "    # Define the optimization\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
    "    N = X_train.shape[0]\n",
    "    # Pick batch size\n",
    "    batch = 32 if N > 1000 else 1     # batch size\n",
    "    history = LossHistory()\n",
    "    # Fit the model\n",
    "    if X_val is None:\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch, validation_split=split,\n",
    "                  callbacks=[history], verbose=verbose)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch, validation_data=(X_val, y_val),\n",
    "                  callbacks=[history], verbose=verbose)\n",
    "    # Evaluate the model on validation data, if any\n",
    "    if X_val is not None or split > 0:\n",
    "        val_acc, val_loss = history.values['epoch_val_acc'][-1], history.values['epoch_val_loss'][-1]\n",
    "        print (\"\\nLoss on validation set:\"  + str(val_loss) + \" Accuracy on validation set: \" + str(val_acc))\n",
    "    else:\n",
    "        val_acc = None\n",
    "    # Evaluate the model on test data, if any\n",
    "    if X_test is not None:\n",
    "        test_loss, test_acc = model.evaluate(X_test, y_test, batch_size=batch)\n",
    "        print (\"\\nLoss on test set:\"  + str(test_loss) + \" Accuracy on test set: \" + str(test_acc))\n",
    "    else:\n",
    "        test_acc = None\n",
    "    return model, history, val_acc, test_acc\n",
    "\n",
    "def dataset_paths(data_name):\n",
    "    return [\"data/data\"+data_name+\"_\"+suffix+\".csv\" for suffix in (\"train\", \"validate\", \"test\")]\n",
    "\n",
    "# The name is a string such as \"1\" or \"Xor\"\n",
    "def run_keras_2d(data_name, layers, epochs, display=True, split=0.25, verbose=True, trials=1):\n",
    "    print('Keras FC: dataset=', data_name)\n",
    "    (train_dataset, val_dataset, test_dataset) = dataset_paths(data_name)\n",
    "    # Load the datasets\n",
    "    X_train, y, num_classes = get_data_set(train_dataset)\n",
    "    X_val, y2, _ = get_data_set(val_dataset)\n",
    "    X_test, y3, _ = get_data_set(test_dataset)\n",
    "    # Categorize the labels\n",
    "    y_train = np_utils.to_categorical(y, num_classes) # one-hot\n",
    "    y_val = y_test = None\n",
    "    if X_val is not None:\n",
    "        y_val = np_utils.to_categorical(y2, num_classes) # one-hot        \n",
    "    if X_test is not None:\n",
    "        y_test = np_utils.to_categorical(y3, num_classes) # one-hot\n",
    "    val_acc, test_acc = 0, 0\n",
    "    for trial in range(trials):\n",
    "        # Reset the weights\n",
    "        # See https://github.com/keras-team/keras/issues/341\n",
    "        session = K.get_session()\n",
    "        for layer in layers:\n",
    "            for v in layer.__dict__:\n",
    "                v_arg = getattr(layer, v)\n",
    "                if hasattr(v_arg, 'initializer'):\n",
    "                    initializer_func = getattr(v_arg, 'initializer')\n",
    "                    initializer_func.run(session=session)\n",
    "        # Run the model\n",
    "        model, history, vacc, tacc, = \\\n",
    "               run_keras(X_train, y_train, X_val, y_val, X_test, y_test, layers, epochs,\n",
    "                         split=split, verbose=verbose)\n",
    "        val_acc += vacc if vacc else 0\n",
    "        test_acc += tacc if tacc else 0\n",
    "        if display:\n",
    "            # plot classifier landscape on training data\n",
    "            plot_heat(X_train, y, model)\n",
    "            plt.title('Training data')\n",
    "            plt.show()\n",
    "            if X_test is not None:\n",
    "                # plot classifier landscape on testing data\n",
    "                plot_heat(X_test, y3, model)\n",
    "                plt.title('Testing data')\n",
    "                plt.show()\n",
    "            # Plot epoch loss\n",
    "            history.plot(['epoch_loss', 'epoch_val_loss'])\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('loss')\n",
    "            plt.title('Epoch val_loss and loss')\n",
    "            plt.show()\n",
    "            # Plot epoch accuracy\n",
    "            history.plot(['epoch_acc', 'epoch_val_acc'])\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('accuracy')\n",
    "            plt.title('Epoch val_acc and acc')\n",
    "            plt.show()\n",
    "    if val_acc:\n",
    "        print (\"\\nAvg. validation accuracy:\"  + str(val_acc/trials))\n",
    "    if test_acc:\n",
    "        print (\"\\nAvg. test accuracy:\"  + str(test_acc/trials))\n",
    "    return X_train, y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4797ca3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras FC: dataset= 1\n",
      "Convert from -1,1 to 0,1\n",
      "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
      "Convert from -1,1 to 0,1\n",
      "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
      "Epoch 1/10\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 2.3242 - accuracy: 0.4900 - val_loss: 1.9471 - val_accuracy: 0.4500\n",
      "Epoch 2/10\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 1.3151 - accuracy: 0.5025 - val_loss: 0.9298 - val_accuracy: 0.4600\n",
      "Epoch 3/10\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.5934 - accuracy: 0.5950 - val_loss: 0.3845 - val_accuracy: 0.7850\n",
      "Epoch 4/10\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.2694 - accuracy: 0.9100 - val_loss: 0.1863 - val_accuracy: 0.9700\n",
      "Epoch 5/10\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.9675 - val_loss: 0.1140 - val_accuracy: 0.9950\n",
      "Epoch 6/10\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.1038 - accuracy: 0.9900 - val_loss: 0.0800 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.0780 - accuracy: 0.9975 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_keras_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 93\u001b[0m, in \u001b[0;36mrun_keras_2d\u001b[0;34m(data_name, layers, epochs, display, split, verbose, trials)\u001b[0m\n\u001b[1;32m     90\u001b[0m             initializer_func\u001b[38;5;241m.\u001b[39mrun(session\u001b[38;5;241m=\u001b[39msession)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Run the model\u001b[39;00m\n\u001b[1;32m     92\u001b[0m model, history, vacc, tacc, \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 93\u001b[0m        \u001b[43mrun_keras\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m val_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m vacc \u001b[38;5;28;01mif\u001b[39;00m vacc \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     96\u001b[0m test_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tacc \u001b[38;5;28;01mif\u001b[39;00m tacc \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[3], line 50\u001b[0m, in \u001b[0;36mrun_keras\u001b[0;34m(X_train, y_train, X_val, y_val, X_test, y_test, layers, epochs, split, verbose)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Evaluate the model on validation data, if any\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m split \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 50\u001b[0m     val_acc, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch_val_acc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, history\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_val_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLoss on validation set:\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(val_loss) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Accuracy on validation set: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(val_acc))\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "run_keras_2d('1', archs(2)[0], 10, display=True, verbose=True, trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e017bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras FC: dataset= 2\n",
      "Convert from -1,1 to 0,1\n",
      "Loading X (400, 2) y (400,) classes {0.0, 1.0}\n",
      "Convert from -1,1 to 0,1\n",
      "Loading X (200, 2) y (200,) classes {0.0, 1.0}\n",
      "Epoch 1/10\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.3800 - accuracy: 0.8250 - val_loss: 0.3452 - val_accuracy: 0.8450\n",
      "Epoch 2/10\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8550 - val_loss: 0.3349 - val_accuracy: 0.8550\n",
      "Epoch 3/10\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3226 - accuracy: 0.8725 - val_loss: 0.3140 - val_accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3061 - accuracy: 0.8800 - val_loss: 0.2949 - val_accuracy: 0.8250\n",
      "Epoch 5/10\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.2848 - accuracy: 0.8800 - val_loss: 0.2674 - val_accuracy: 0.8950\n",
      "Epoch 6/10\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.2763 - accuracy: 0.9000 - val_loss: 0.2536 - val_accuracy: 0.8850\n",
      "Epoch 7/10\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2636 - accuracy: 0.9025 - val_loss: 0.2412 - val_accuracy: 0.8950\n",
      "Epoch 8/10\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.2464 - accuracy: 0.9050 - val_loss: 0.2287 - val_accuracy: 0.8950\n",
      "Epoch 9/10\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.2256 - accuracy: 0.9250 - val_loss: 0.2096 - val_accuracy: 0.9150\n",
      "Epoch 10/10\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1984 - accuracy: 0.9275 - val_loss: 0.2422 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_keras_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 93\u001b[0m, in \u001b[0;36mrun_keras_2d\u001b[0;34m(data_name, layers, epochs, display, split, verbose, trials)\u001b[0m\n\u001b[1;32m     90\u001b[0m             initializer_func\u001b[38;5;241m.\u001b[39mrun(session\u001b[38;5;241m=\u001b[39msession)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Run the model\u001b[39;00m\n\u001b[1;32m     92\u001b[0m model, history, vacc, tacc, \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 93\u001b[0m        \u001b[43mrun_keras\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m val_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m vacc \u001b[38;5;28;01mif\u001b[39;00m vacc \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     96\u001b[0m test_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tacc \u001b[38;5;28;01mif\u001b[39;00m tacc \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[3], line 50\u001b[0m, in \u001b[0;36mrun_keras\u001b[0;34m(X_train, y_train, X_val, y_val, X_test, y_test, layers, epochs, split, verbose)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Evaluate the model on validation data, if any\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m split \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 50\u001b[0m     val_acc, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch_val_acc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, history\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_val_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLoss on validation set:\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(val_loss) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Accuracy on validation set: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(val_acc))\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "run_keras_2d('2', archs(2)[4], 10, display=True, split=0, verbose=True, trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    data_name = str(i)\n",
    "    for i in range(5):\n",
    "        run_keras_2d(data_name, archs(2)[i], 10, display=True, split=0, verbose=True, trials=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
